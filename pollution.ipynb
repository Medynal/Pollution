{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOJlwIWzSXHgKclq5UdqQmm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Medynal/Pollution/blob/main/pollution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Medynal/Pollution.git"
      ],
      "metadata": {
        "id": "0HSmYElfdhU9",
        "outputId": "9a4fc848-443b-401f-cb1c-fe96f83f627c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Pollution' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KWJPnoNpXF0s",
        "outputId": "535c6d3e-c319-46b8-8115-bf59bc16989c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.20.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.12/dist-packages (from gdown) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2025.11.12)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file 1KFDJiZmhgbjSW7xGmWP7yzxoQnm-38a0 Ahmedabad_data.csv\n",
            "Processing file 19vlL9i6x-vZU4ctApF4p5-MF-TLTMkeu Aizawl_data.csv\n",
            "Processing file 1BhBvdHklAievoh0IJBtqRLXMq7SKNm_Y Amaravati_data.csv\n",
            "Processing file 1v0us8qYW1CKJjN_7sBevoC0aw7bJsCqB Amritsar_data.csv\n",
            "Processing file 1flxEMgV9JJAB7WzCKLKK4pBfB9D_aQ0l Bengaluru_data.csv\n",
            "Processing file 1dZgKMW_hGX50h292KbH2aUObjypgX7O8 Bhopal_data.csv\n",
            "Processing file 1PyFb5ZE3nJFdSYqmEuGcY1DsbVq2jihO Brajrajnagar_data.csv\n",
            "Processing file 1byKiqT-hEN0IOXMfn2Wu3S65giQkGtK7 Chandigarh_data.csv\n",
            "Processing file 18Cl3dgp_7TVbEJrhJ6woRjBv2QRQh0np Chennai_data.csv\n",
            "Processing file 12l_Fd0Wv2YCSefvVXKrgBhiVud5ITEO5 Coimbatore_data.csv\n",
            "Processing file 1fXTwPr782EJo3IJq8gb-nUYi0VBDEbfk Delhi_data.csv\n",
            "Processing file 1OqbcppqTkahM7QRYDmE4iEZRyNQJx8vU Ernakulam_data.csv\n",
            "Processing file 1erU1gOL6f-iNpAbtT92f-NQIpC4nK5Ed Gurugram_data.csv\n",
            "Processing file 16iTfGdXEjcJtx8BrYwq90mulJXwvtGfA Guwahati_data.csv\n",
            "Processing file 19duFvC3Pq3izBse2iF4ZLwfWrAhchlsc Hyderabad_data.csv\n",
            "Processing file 1Zw3qy0aGXDtn2ps1aj_sen18_dzZtRxL Jaipur_data.csv\n",
            "Processing file 1RO125B7nSl9SXxwIhpq7J-YEgiwWDmhH Jorapokhar_data.csv\n",
            "Processing file 14ieutsxrgs25YF9BZPueSggXN_zFT8tg Kochi_data.csv\n",
            "Processing file 1JW5Qb4opw67BZuXbtBTWpcizpUJlG04Y Kolkata_data.csv\n",
            "Processing file 1Vp87ppcPeCM8l57DIyhxx-zsUyfO_ile Lucknow_data.csv\n",
            "Processing file 1Di8LajXzhjkZm2PcYvMB-vzHMeIYPPrs Mumbai_data.csv\n",
            "Processing file 1_yHmM_UzhlxD1NqBlK0d6PYUaXtQAk-a Patna_data.csv\n",
            "Processing file 1o4sVbDZrVBO6uVwGo0GUYx3KlyfR8SfJ Shillong_data.csv\n",
            "Processing file 1XTNG98Q8s8Wu6562lw1t-dbTTYz0Gbt7 Talcher_data.csv\n",
            "Processing file 1likofzqoj4gdFC9NQohZgCK3jcah6pfP Thiruvananthapuram_data.csv\n",
            "Processing file 1GocDfbR4e1ofjq24elFRDJrjL-gPCAiU Visakhapatnam_data.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileURLRetrievalError",
          "evalue": "Failed to retrieve file url:\n\n\tCannot retrieve the public link of the file. You may need to change\n\tthe permission to 'Anyone with the link', or have had many accesses.\n\tCheck FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.\n\nYou may still be able to access the file from the browser:\n\n\thttps://drive.google.com/uc?id=1KFDJiZmhgbjSW7xGmWP7yzxoQnm-38a0\n\nbut Gdown can't. Please check connections and permissions.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileURLRetrievalError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gdown/download.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(url, output, quiet, proxy, speed, use_cookies, verify, id, fuzzy, resume, format, user_agent, log_messages)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_url_from_gdrive_confirmation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileURLRetrievalError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gdown/download.py\u001b[0m in \u001b[0;36mget_url_from_gdrive_confirmation\u001b[0;34m(contents)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         raise FileURLRetrievalError(\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0;34m\"Cannot retrieve the public link of the file. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileURLRetrievalError\u001b[0m: Cannot retrieve the public link of the file. You may need to change the permission to 'Anyone with the link', or have had many accesses. Check FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileURLRetrievalError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2332599261.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgdown\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgdrive_link\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://drive.google.com/drive/folders/1pMpViNUBVnC4xB4fTtYF9VHwp7c9Ms7b?usp=sharing'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mgdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgdrive_link\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'pollution_dataset'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'download complete!'\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gdown/download_folder.py\u001b[0m in \u001b[0;36mdownload_folder\u001b[0;34m(url, id, output, quiet, proxy, speed, use_cookies, remaining_ok, verify, user_agent, skip_download, resume)\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m             local_path = download(\n\u001b[0m\u001b[1;32m    326\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"https://drive.google.com/uc?id=\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                 \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gdown/download.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(url, output, quiet, proxy, speed, use_cookies, verify, id, fuzzy, resume, format, user_agent, log_messages)\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0murl_origin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m             )\n\u001b[0;32m--> 278\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileURLRetrievalError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0mfilename_from_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileURLRetrievalError\u001b[0m: Failed to retrieve file url:\n\n\tCannot retrieve the public link of the file. You may need to change\n\tthe permission to 'Anyone with the link', or have had many accesses.\n\tCheck FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.\n\nYou may still be able to access the file from the browser:\n\n\thttps://drive.google.com/uc?id=1KFDJiZmhgbjSW7xGmWP7yzxoQnm-38a0\n\nbut Gdown can't. Please check connections and permissions."
          ]
        }
      ],
      "source": [
        "!pip install gdown -U --no-cache-dir\n",
        "from pathlib import Path\n",
        "import gdown\n",
        "gdrive_link = 'https://drive.google.com/drive/folders/1pMpViNUBVnC4xB4fTtYF9VHwp7c9Ms7b?usp=sharing'\n",
        "gdown.download_folder(gdrive_link, output= 'pollution_dataset', quiet= False)\n",
        "print ('download complete!' )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the necessary libraries for data analysis\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "7AHToE3ddT_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframes = []\n",
        "for filename in os.listdir('pollution_dataset'):\n",
        "    if filename.endswith('.csv'):  # Check if the file is a CSV file\n",
        "        file_path = os.path.join('pollution_dataset', filename)\n",
        "        df = pd.read_csv(file_path)  # Read the CSV file into a DataFrame\n",
        "        dataframes.append(df)  # Add the DataFrame to the list"
      ],
      "metadata": {
        "id": "BvyDgDylbgKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_df = pd.concat(dataframes, ignore_index=True)\n",
        "pollution_df"
      ],
      "metadata": {
        "id": "1LzBBjftczlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print ('shape', pollution_df.shape )\n",
        "\n",
        "def unique_col(df):\n",
        "  for column in df.columns:\n",
        "    print (f'{column}: {df[column].nunique()}')\n",
        "\n",
        "print(f'\\nnumber of unigue value in each column')\n",
        "unique_col(pollution_df)\n",
        "print ('\\n')\n",
        "pollution_df.info()"
      ],
      "metadata": {
        "id": "ZXRWotTThGXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def missing_values_table(df):\n",
        "    mis_val = df.isnull().sum() # Total missing values\n",
        "    mis_val_percent = 100 * mis_val / len(df)  # Percentage of missing values\n",
        "    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
        "    mis_val_table = mis_val_table.rename(columns={0: 'Missing Values', 1: '% of Total Values'})\n",
        "    mis_val_table = mis_val_table.sort_values('% of Total Values', ascending=False)  # Sort the table by percentage of missing descending\n",
        "    return mis_val_table\n",
        "\n",
        "missing_values = missing_values_table(pollution_df)\n",
        "display(missing_values.style.background_gradient(cmap='Blues'))"
      ],
      "metadata": {
        "id": "yrFBuV8Ulfy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_df['Date']= pd.to_datetime(pollution_df['Date'], errors= 'raise',format= '%d/%m/%Y')\n",
        "pollution_df['year']= pollution_df['Date'].dt.year\n",
        "pollution_df['month']= pollution_df['Date'].dt.month\n",
        "pollution_df['day']= pollution_df['Date'].dt.day\n",
        "pollution_df['Month name']= pollution_df['Date'].dt.month_name()\n"
      ],
      "metadata": {
        "id": "9-h_8aOTw-Zr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_values_per_city = pollution_df.groupby('City').apply(lambda x: x.isnull().sum())\n",
        "missing_values_per_city"
      ],
      "metadata": {
        "id": "21K0eNr8yP7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize= (10,6))\n",
        "sns.heatmap(missing_values_per_city)\n",
        "plt.xlabel('Pollutant')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pamDLD3E67nU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_df= pollution_df.sort_values(['City', 'Date'],ascending= [True, True])"
      ],
      "metadata": {
        "id": "-tkdgsSEkgj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pollutants = [\"PM2.5\",\"PM10\",\"NO\",\"NO2\",\"NOx\",\"NH3\",\"CO\",\"SO2\",\"O3\",\n",
        "              \"Benzene\",\"Toluene\",\"Xylene\", \"AQI\", \"AQI_Bucket\"]\n",
        "\n",
        "pollution_df[pollutants] = pollution_df.groupby(['City', 'year'])[pollutants].ffill().bfill()\n",
        "pollution_df.isna().sum()"
      ],
      "metadata": {
        "id": "Wu3SIooNQjzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pollution_df.head(20)"
      ],
      "metadata": {
        "id": "lwdGp3Ljlesg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_df.describe().T"
      ],
      "metadata": {
        "id": "DEgDX73BsKIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "pollutant_columns = ['PM2.5','PM10','NO2','NOx','NH3','CO', 'SO2','O3', 'Benzene', 'Toluene', 'Xylene']\n",
        "\n",
        "#Group by station and calculate mean pollutant concentrations\n",
        "mean_pollutant_by_city =pollution_df.groupby('City')[pollutant_columns].mean()\n",
        "\n",
        "#Find the top 5 stations for each pollutant\n",
        "top_city = {}\n",
        "for pollutant in pollutant_columns:\n",
        "    top_city[pollutant] = mean_pollutant_by_city[pollutant].sort_values(ascending=False).head(5)\n",
        "\n",
        "# Step 3: Plotting\n",
        "fig, axes = plt.subplots(len(pollutant_columns), 1, figsize=(10, 20))\n",
        "\n",
        "for i, pollutant in enumerate(pollutant_columns):\n",
        "    axes[i].barh(top_city[pollutant].index, top_city[pollutant].values, color='red')\n",
        "    axes[i].set_title(f'Top 5 Cities by {pollutant}')\n",
        "    axes[i].set_xlabel(f'{pollutant}')\n",
        "    axes[i].invert_yaxis()  # Highest values on top\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kP0E0dl-RpBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pollutants = ['PM2.5','PM10','NO2','NOx','NH3','CO', 'SO2','O3', 'Benzene', 'Toluene', 'Xylene']\n",
        "cities = pollution_df['City'].unique()\n",
        "\n",
        "for city in cities:\n",
        "    city_data = pollution_df[pollution_df['City'] == city]\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    for pollutant in pollutants:\n",
        "        plt.bar(pollutant, city_data[pollutant].mean(), label=pollutant)\n",
        "    plt.title(f'Average Pollutant Levels at Station {city}')\n",
        "    plt.xlabel('Pollutant')\n",
        "    plt.ylabel('Average Concentration')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "6LZIE2vIW41d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " city_stats = pollution_df.groupby('City')[pollutants].mean().reset_index()\n",
        "\n",
        "import plotly.express as px\n",
        "\n",
        "# Melt the DataFrame to create a 'Pollutant' column\n",
        "city_stats_melted = city_stats.melt(id_vars='City',\n",
        "                               value_vars=pollutants,\n",
        "                               var_name='Pollutant',\n",
        "                               value_name='Average Concentration')\n",
        "\n",
        "# Create the stacked bar chart\n",
        "fig_cities= px.bar(city_stats_melted,\n",
        "                     x='City',\n",
        "                     y='Average Concentration',\n",
        "                     color='Pollutant', # Use 'Pollutant' for color differentiation\n",
        "                     title='Average Pollution Levels by City (Stacked)',\n",
        "                     labels={'City': 'Cities', 'Average Concentration': 'Average Concentration'},\n",
        "                     barmode='stack')\n",
        "\n",
        "fig_cities.show()"
      ],
      "metadata": {
        "id": "zTx0oelurhxI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}